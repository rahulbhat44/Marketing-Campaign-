### Load the required libraries
library(ggplot2) # For visualization
library(tidyverse) # preparing, wrangling and visualizing data.
library(lubridate) # For date-time objects
library(dplyr) # Data Wrangling and Transformation


### Marketing campaign dataset
# Import the dataset
df <- read.csv("marketing_campaigns.csv",header=TRUE,stringsAsFactors = F, sep=";")
summary(df)

### Problem Statement (a): Overview of entire marketâ€™s development and the different campaigns.

# Inspect the dataset
str(df)

# Shows the dimensions
dim(df)  

# shows the variable names
names(df) 

# shows the top 6 obs
head(df) 

# shows the last 6 obs
tail(df)

### Check for missing data

is.na(df) 

# There is no missing data

### Now let's check for the duplicates and remove them
duplicated(df) 

# There is one in the last row 91st week 30. 

df <- df[-91,] # remove 91st row
tail(df) # check again

#### 1. Visualizing the dataset to get some insight into the campaigns for 30 weeks using 
# the package Plotly. Plotly generates interactive charts. If we move the cursor on the chart, 
# we can see the results. 

library(plotly)

### 1.1 Visualize the visits per week for each campaign

p <- plot_ly(df, x = ~Week, y=~Visits, color = ~Campaign)
p

#### 1. Aldebaran Campaign

#### The plot shows that the Aldebaran campaign had only 27 visits in the first week, 
# 64 visits in the second week which is more than the double. Later, This campaign showed a 
# tremendous increase in the visits and has attracted more visitors to the campaign 
# i.e 613 during last week (30th week).

#### 2. Bartledan Campaign

#### Bartledan had 128 visits during the first week which is very high as compare to Aldebaran. During the third week, it came down to 99 and then very slowly started increasing and got only 247 visits during the last week. 

#### 3. Cottington campaign

##### The Cottington campaign had 149 visits in the first week, which is higher than the 
# rest two Aldebaran and Bartledan. In the last week, the visits decreased to 125 which is 
# the lowest amongst all.


### 1.2 Visualize the cost spent on each campaign

p <- plot_ly(df, x = ~Campaign, y=~Cost, color = ~Campaign)
p

#### From the above chart we can see that the cost spent on the cottington campaign is very 
# high followed by Bartledan and Aldebaran. The total cost spent on Aldebaran is very low as compare to the other two campaigns. 


### 1.3 Visualize the revenue generated by each campaign

p <- plot_ly(df, x = ~Campaign, y=~Revenue, color = ~Campaign)
p
```

#### From the above chart we can see that the Cottington Campaign has generated more revenue followed by Bartledan and Aldebaran.


### 1.4 Visualize the profit for each campaign, but first, we have to calculate the profit. 

#### Profit = Revenue - Cost


prof <- df %>% 
  mutate(Profit = Revenue - Cost)


# Check which campaign got the maximum and minimum profit
p <- plot_ly(prof, x = ~Campaign, y=~Profit, color = ~Campaign)
p

#### The profit chart shows that the Cotttington Campaign got the highest profit amongst all. 

#### Aldebaran got some profit in the end but it is almost no profit no loss.

#### The Bartledan is in loss and the worst amongst all.   


### Problem Statement (b): How would you assess the development of the quality of traffic, e.g. in terms of revenue per visitor. How is the overall development and how does each campaign evolve?

##### To answer this we have to create few metrics, we will calculate Revenue Per Visitor, Cost Per Visitor, Profit Per Visitor and Overall Campaign Profit. This will give us a clear picture of the campaign. 

### 1.5 Calculate Revenue Per Visitor

##### Revenue per Visitor (RPV) is a measurement of the amount of money generated each time a customer visits the website. Formula to calculate RPV is by dividing the total revenue by the total number of visitors visit the site and is a method of estimating the value of each additional visitor. We have weekly data so we will calculate weekly revenue per visitor


# Calculate RPV using the formaula RPV = Revenue / Visits
rpv <- prof %>% 
  mutate(RPV = Revenue / Visits)

# Visualize Weekly Revenue Per Visitor using Line Chart
p <- plot_ly(rpv, x = ~Week, y=~RPV, color = ~Campaign, type = 'scatter', 
             mode = 'lines')
p

##### NOTE: To see the values please move the cursor in the chart. 

#### As we can see that the Cottington campaign has generated maximum revenue of 2.85 per visitor followed by Bartledan and Aldebaran at 1.65 and 0.42. When we visualized the visits per week for each campaign, we saw that the Cottington had 149 visits in the first week, which was higher than the rest two Aldebaran and Bartledan. In the last weeks, the visits decreased to 125 which was the lowest among all. Even after less number of visitors, Cottington campaign got the highest RPV amongst all the three campaigns.

#### The revenue per visitor doesn't show us the clear picture of the campaign, the cost spent on the campaign is also a very important factor. As we have already seen above the cost spent on Cottington and Bartledan was very high. 

### 1.6 Calculate the Cost Per Visitor.

#### Now we will calculate the cost per visitor in the same way we calculated revenue per visitor. 


# Calculate RPV using the formaula RPV = Revenue / Visits
cpv <- prof %>% 
  mutate(CPV = Cost / Visits)


# Visualize Weekly Revenue Per Visitor using Line Chart
p <- plot_ly(cpv, x = ~Week, y=~CPV, color = ~Campaign, type = 'scatter', 
             mode = 'lines')
p

#### As we can see in the above plot that the cost spent per visitor is very high for Cottington (3.11) and Bartledan (1.78). The cost spent per visitor for Aldebaran is very low as compare to the other two and that is 0.34. This metric tells us what is the cost spent to attract one visitor. This should be as low as possible to generate more profit per visitor. 

### 1.7 Calculate Profit Per Visitor. 


# Calculate RPV using the formaula RPV = Revenue / Visits
ppv <- prof %>% 
  mutate(PPV = Profit / Visits)


# Visualize Weekly Revenue Per Visitor using Line Chart
p <- plot_ly(ppv, x = ~Week, y=~PPV, color = ~Campaign, type = 'scatter', 
             mode = 'lines')
p

#### Now we can see clearly the insight of the development in terms of traffic which is totally different from the Revenue Per Visitor. The plot above shows that there is actually no profit generated by Cottington and Bartledan, instead, they are in loss. The Aldebaran campaign generated the profit after the 20th week. The Aldebaran generated the highest profit of 0.07 per visitor which is far better than the other two campaigns. The plot shows that the Bartledan is at loss of 0.13 per visitor and Bartledan is at loss of 0.26 per visitor.

### 1.8 Let's calculate the Overall Campaign Profit

over_profit <- rpv%>% 
  select(Week, Campaign, Revenue, Cost) %>% 
  pivot_longer(cols = Revenue:Cost, names_to ="CostRevenue" ,values_to = "Value") %>% 
  group_by(Campaign,CostRevenue) %>% 
  summarise(Value = round(sum(Value),1))
over_profit


# Plot the overall profit
p <- plot_ly(over_profit, x = ~Campaign, y=~Value, color = ~CostRevenue)
p

#### The overall campaign profit shows that the cottington generated the highest profit. Barteladen is in loss and the Aldebaran is almost no profit no loss.  

### The overall summary of the campaign. 

#### Aldebaran:

##### The Aldebaran started with the loss. Aldebaran campaign had very low visits in the first week, but in the second week, it was more than double. 

##### The revenue generated per visitor increased by 2.5 folds from week 1 to 30.

##### After week 20 this campaign showed a tremendous increase in the visits and has attracted more visitors to the campaign and in the end it had the best quality of traffic.

#### Bartledan:

##### Bartledan had 128 visits during the first week. During the third week, it went down to 99 and then very slowly started increasing and got only 247 visits during the last week.

##### The cost spent on this campaign was the second-highest and according to the Profit Per Visitor, it started the campaign with the highest loss amongst all and continued to same until week 26. Even after 26 weeks, it couldn't generate much profit.

##### The revenue generated per visitor increases by nearly 1.6 times from week 1 to week 30. 

##### The least loss it incurred was in the 4th week of 7.28. This campaign was the worst of all.

#### Cottington.

##### The Cottington campaign had the highest visits of 149 in the first week. In the last week, the visits decreased to 125 which was the lowest amongst all. Even after less number of visitors, Cottington campaign got the highest RPV amongst all the three campaigns.

##### The increase in revenue per visitor was steady from week 1 to 29, but suddenly after week 30, there was an unusual increase in the revenue that was due to the unusual increase in the cost spent.  

##### The revenue generated per visitor increases by nearly 1.5 times from week 1 to 30. 

#####  Cottington was the only campaign that generated the highest profit from week 1 but it started felling down gradually and generated the most loss per week.

##### After week 20 it couldn't generate profits. 


### 1.7 Advice in which campaign to invest and why?

#### Based on our findings I would advise the business developer to invest in Aldebaran campaign because if an investor spends more in the Aldebaran campaign, it will generate more profit. The cost spent on Aldebaran was very low and still, it generated some profit in the end. If the investor will spend more in Aldebaran it will definitely generate more profit. 

### 1.8 How do you expect this to impact the overall performance in the market from week 31 onwards?

#### Let's try the regression Model to predict a campaign profit. Let's see if it works

model1 <- lm(Profit ~ Campaign, data = rpv)
summary(model1)

#### With reference to this model summary, we have Residual standard error as 20.58, which should be as small as possible (logically with value 0 denotes perfect prediction). Where Multiple R squared as 0.3794 which denotes this model has nearly 38% prediction accuracy. 

#### We can see that CampaignBartledan shows a significant profit of approx 9.8 and CampaignBartledan shows a negative -27.58, which means there will be a loss if invested on Bartledan Campaign. 

#### For Aldebaran there is almost no profit no loss.

#### Cottington will surely do more profit after 31 weeks, but there is one thing to notice and that is Aldebaran also did very good and the cost spent on Aldebaran was also very less and it generated profit as well, which was not much but still its a profit.

#### Aldebaran is progressing and might generate more profit in the next weeks but it would be slow but the investment is also less as compare to others. 


###########################################################################################

### 2.0 Session Data

## Avoidance of scientific numbers
options(scipen = 999)


# Import the session dataset
df_sessions <- read.csv("session_data.csv",header=TRUE,stringsAsFactors = F, sep=",")
summary(df_sessions)

#### Data Exploration and Preparation
# Inspect the dataset
str(df_sessions) 

# I think we need to change the time format, its a character here. 

dim(df_sessions) 

# shows the top 6 obs
head(df_sessions) 

# shows the last 6 obs
tail(df_sessions) 

#### While proceeding the session dataset, it couldn't work because the time is in a character format and we need to change that in a correct format. We will use a package called "hms" which provides a simple class for storing durations or time-of-day values and displaying them in the hh:mm:ss format.

library(hms)
df_sessions$session_start_text <- as_hms(df_sessions$session_start_text)
df_sessions$session_end_text <- as_hms(df_sessions$session_end_text)
str(df_sessions)

### 2.1 Now we will calculate the time duration of a session in minutes (between session start and session end)


df_sessions <- df_sessions %>%
  mutate(duration = 
           round(as.numeric(( session_end_text - session_start_text)/60)))

head(df_sessions)

### 2.2 We can see that the column duration is generated and showing the time duration of a session in minutes. 


#### Let's count the number of bookings for 0 and 1

df_sessions %>%
  group_by(booking) %>%
  summarise(count = n())


### 2.3 Let's count the number of clickouts

df_sessions %>%
  group_by(clickouts) %>%
  summarise(count = n())

#### As we can see there are mostly are 2 and 3 clickouts.

### 2.4 Let's count the durations

df_sessions %>%
  group_by(duration) %>%
  summarise(count = n())

#### The duration above shows negative values, it looks like a bug or R has interpreted it in a wrong way. After analyzing the problem and after long research I found out that we need to convert the minutes to seconds by adding 86400 seconds (86400 number of seconds in 24 hours), which will give us the number of seconds instead of minutes. 

#### For example

##### -1438*60 = -86280

##### 86400-86280 = 120 seconds (2 minutes)

df_sessions$duration[df_sessions$duration==-1438] = 2
df_sessions$duration[df_sessions$duration==-1437] = 3
df_sessions$duration[df_sessions$duration==-1436] = 4
df_sessions$duration[df_sessions$duration==-1435] = 5

### 2.5 Now we can check if it's showing correct or not

df_sessions %>%
  group_by(duration) %>%
  summarise(count = n())

#### we can see that its showing correct values now.

### 2.6 Visualize the session dataset for the distribution of booking with clickouts and duration using ggplot. 

df_sessions %>%
  group_by(booking, clickouts) %>%
  summarise(count = n()) %>%
  ggplot() + geom_bar(aes(x = clickouts, y = count, 
                          fill = booking), stat = "identity") + 
  guides(fill = guide_legend(title = "Booking")) + 
  facet_grid(. ~ booking) +
  labs(x = "clickouts", y = "booking", 
       title = "Booking w.r.t Clickouts")

##### As we can see in the above plot the booking data is normally distributed with respect to clickouts. We can also see that most of the bookings are done in 2 and 3 clickouts. 

### 2.7  Now let's check for the time duration.

df_sessions %>%
  group_by(booking, duration) %>%
  summarise(count = n()) %>%
  ggplot() + geom_bar(aes(x = duration, y = count, 
                          fill = booking), stat = "identity") + 
  guides(fill = guide_legend(title = "Booking")) + 
  facet_grid(. ~ booking) +
  labs(x = "Session Minutes", y = "Booking", 
       title = "Booking w.r.t Duration")

#### This plot also shows that the booking data is normally distributed concerning time duration. We can see that most of the bookings are done in 3 minutes. 

#### Now we can say that there is a relation between booking and duration and booking and clickouts as well. We can do the Hypothesis test to see the relationship between them, let's see if we can prove the hypothesis test. 

### 2.8 But first let's check the correlation between these variables using the correlation matrix. Let's see what the correlation matrix says before doing the hypothesis.

## Generate the correlation matrix
cor <- cor(df_sessions %>% select(booking, clickouts, duration))
cor
plot(cor)

#### The correlation plot above shows that there is no relation between them. That's interesting to see, when we visualized the distribution plot it showed a relation between them and now in a correlation matrix plot, it shows there is no relation at all. It would be interesting to do the hypothesis test to check and verify what it is, is there any relation or not. 

### 2.8 Hypothesis Test

#### In our case the null hypothesis(H0) and the alternative hypothesis(H1) would be:

##### H0: There is no relation between Booking and (duration/clickouts).
##### H1: It rejects that there is a relation between Booking and (duration/clickouts).

model = glm(booking ~ duration + clickouts, data = df_sessions
            , family = binomial(link = "logit"))
summary(model)


#### The P-Value for the duration is 0.178 which is very large i.e greater than 0.05. The P-value should be smaller than alpha and the value of alpha is 0.05 which means we fail to reject the null hypothesis. So it proves that there is no relation between booking and duration.

#### The P-value for clickouts is 0.000000499 and we already said above that it should be smaller than alpha value i.e 0.05. So we reject the null hypothesis and we can say that we have evidence to prove that there is a relation between these booking and clickouts.



